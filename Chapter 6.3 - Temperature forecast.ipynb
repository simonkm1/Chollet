{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Model definition\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# SKLEARN\n",
    "from sklearn.preprocessing  import ( StandardScaler, )\n",
    "from sklearn.model_selection import ( train_test_split,KFold,cross_val_score, )\n",
    "\n",
    "#KERAS \n",
    "from keras import backend\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "from keras.layers import (Dense,Flatten,Embedding, SimpleRNN, LSTM, GRU, )\n",
    "from keras.models import (load_model,Sequential, )\n",
    "from keras.applications import (VGG16,)\n",
    "from keras.preprocessing.image import (ImageDataGenerator,image,)\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.datasets import (boston_housing,mnist, imdb,)\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#from utils import plot_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"Date Time\"', '\"p (mbar)\"', '\"T (degC)\"', '\"Tpot (K)\"', '\"Tdew (degC)\"', '\"rh (%)\"', '\"VPmax (mbar)\"', '\"VPact (mbar)\"', '\"VPdef (mbar)\"', '\"sh (g/kg)\"', '\"H2OC (mmol/mol)\"', '\"rho (g/m**3)\"', '\"wv (m/s)\"', '\"max. wv (m/s)\"', '\"wd (deg)\"']\n",
      "(420551, 14)\n",
      "                 0             1             2             3             4   \\\n",
      "count  4.205510e+05  4.205510e+05  4.205510e+05  4.205510e+05  4.205510e+05   \n",
      "mean  -3.518031e-13  6.626287e-15  4.186531e-13 -9.558809e-16  2.610831e-14   \n",
      "std    1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00   \n",
      "min   -9.046245e+00 -3.853589e+00 -3.867705e+00 -4.452138e+00 -3.827243e+00   \n",
      "25%   -5.997241e-01 -7.230073e-01 -7.128898e-01 -7.006519e-01 -6.553871e-01   \n",
      "50%    4.393434e-02 -3.579020e-03 -2.674296e-03  3.924517e-02  1.997881e-01   \n",
      "75%    6.588794e-01  7.146621e-01  7.098929e-01  7.598276e-01  8.127952e-01   \n",
      "max    3.127034e+00  3.303892e+00  3.274429e+00  2.697229e+00  1.456149e+00   \n",
      "\n",
      "                 5             6             7             8             9   \\\n",
      "count  4.205510e+05  4.205510e+05  4.205510e+05  4.205510e+05  4.205510e+05   \n",
      "mean  -1.310638e-13  5.966686e-15 -5.997504e-14  5.695925e-14 -4.282757e-14   \n",
      "std    1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00   \n",
      "min   -1.631507e+00 -2.089728e+00 -8.255135e-01 -2.079114e+00 -2.087228e+00   \n",
      "25%   -7.489653e-01 -7.943665e-01 -6.478481e-01 -7.915289e-01 -7.910070e-01   \n",
      "50%   -2.269348e-01 -1.610254e-01 -3.782867e-01 -1.627960e-01 -1.606046e-01   \n",
      "75%    5.199307e-01  6.730729e-01  2.568161e-01  6.692398e-01  6.728488e-01   \n",
      "max    6.485809e+00  4.489849e+00  8.570332e+00  4.558348e+00  4.528456e+00   \n",
      "\n",
      "                 10            11            12            13  \n",
      "count  4.205510e+05  4.205510e+05  4.205510e+05  4.205510e+05  \n",
      "mean  -2.278932e-13  2.517855e-17 -6.271194e-16 -2.304008e-14  \n",
      "std    1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00  \n",
      "min   -3.917752e+00 -1.528070e+02 -1.449220e+02 -2.015927e+00  \n",
      "25%   -7.147626e-01 -1.088251e-02 -1.878607e-02 -5.750210e-01  \n",
      "50%   -5.685400e-02  8.827979e-04 -1.399010e-03  2.694489e-01  \n",
      "75%    6.680962e-01  1.769038e-02  2.439179e-02  6.847620e-01  \n",
      "max    4.439688e+00  4.093072e-01  2.962095e-01  2.137204e+00  \n"
     ]
    }
   ],
   "source": [
    "# download from  https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip\n",
    "jena = r'G:\\STUDY\\Chollet - Deep LEarning With Python - Keras\\jena_climate_2009_2016.csv'\n",
    "\n",
    "with open(jena) as file:\n",
    "    data = file.read()\n",
    "\n",
    "lines = data.split('\\n')\n",
    "header = lines[0].split(\",\")\n",
    "lines = lines[1:]\n",
    "\n",
    "print(header)\n",
    "data = np.zeros((len(lines), len(header) - 1))\n",
    "# not including DateTime first column\n",
    "for i, line in enumerate(lines):\n",
    "    data[i,:] = [float(x) for x in line.split(\",\")[1:]]\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "scaler = StandardScaler(copy = False)\n",
    "scaler.fit(data)\n",
    "scaler.transform(data)\n",
    "\n",
    "# verify the scaler\n",
    "#print (pd.DataFrame(data).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is 10 mins interval\n",
    "def generator(data, lookback, delay, start_index, end_index, shuffle=False, batch_size=128,step = 6):\n",
    "    if end_index is None:\n",
    "        end_index = len(data) - delay -1\n",
    "        \n",
    "    i = start_index + lookback\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(start_index + lookback, end_index, size = batch_size)\n",
    "        else:\n",
    "            if i + batch_size >= end_index:\n",
    "                i = start_index + lookback\n",
    "            rows = np.arange(i, min(i + batch_size, end_index))\n",
    "            i += len(rows)\n",
    "        samples = np.zeros((len(rows), lookback// step, data.shape[-1]))\n",
    "        targets =  np.zeros((len(rows),))\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            samples[j] = data[indices]\n",
    "            targets[j] = data[rows[j] + delay][1]\n",
    "        yield samples, targets\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 6\n",
    "delay = 24 * 6         # points in 1 day\n",
    "lookback = 10 * delay  # points in 10 days\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_gen = generator(data,lookback, delay, start_index = 0, end_index = 200000, \n",
    "                      shuffle=True,step=step,batch_size=batch_size)\n",
    "\n",
    "valid_gen = generator(data,lookback, delay, start_index = 200001, end_index = 300000, \n",
    "                      step=step,batch_size=batch_size)\n",
    "\n",
    "test_gen = generator(data,lookback, delay, start_index = 300001, end_index = None, \n",
    "                      step=step,batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFN achieves 0.3 loss on validation  data\n",
    "# GRU achieves 0.26 loss on validation data\n",
    "def build_model(gru = True):\n",
    "    model = Sequential()\n",
    "    if gru:\n",
    "        model.add(GRU(32,input_shape = (None,data.shape[-1])))\n",
    "    else:\n",
    "        model.add(Flatten(input_shape = (lookback//step, data.shape[-1])))\n",
    "        model.add(Dense(32, activation=\"relu\"))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss = 'mae')\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 32)                4512      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 4,545\n",
      "Trainable params: 4,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 29s 58ms/step - loss: 0.3212 - val_loss: 0.2291\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 29s 57ms/step - loss: 0.2992 - val_loss: 0.2353\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 28s 57ms/step - loss: 0.2948 - val_loss: 0.3063\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 29s 58ms/step - loss: 0.2886 - val_loss: 0.2942\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 29s 57ms/step - loss: 0.2841 - val_loss: 0.1973\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "history = model.fit_generator(train_gen, epochs = 5, steps_per_epoch = 500, validation_data = valid_gen, validation_steps=10)\n",
    "model.save(\"gru_trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
